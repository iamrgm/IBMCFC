{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "training CNN-LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-I_BUNtyZpS",
        "colab_type": "code",
        "outputId": "8b6e58f1-ea89-4512-df69-9c3c0b1d8321",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "path = \"drive/My Drive/CNN-LSTM/flickr30k_images/\"\n",
        "import numpy as np\n",
        "from numpy import array\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import string\n",
        "import os\n",
        "from PIL import Image\n",
        "import glob\n",
        "from pickle import dump, load\n",
        "from time import time\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Embedding, TimeDistributed, Dense, RepeatVector,\\\n",
        "                         Activation, Flatten, Reshape, concatenate, Dropout, BatchNormalization\n",
        "from keras.optimizers import Adam, RMSprop\n",
        "from keras.layers.wrappers import Bidirectional\n",
        "from keras.layers.merge import add\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from keras.preprocessing import image\n",
        "from keras.models import Model\n",
        "from keras import Input, layers\n",
        "from keras import optimizers\n",
        "from keras.applications.inception_v3 import preprocess_input\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ly-F9AfGyn5J",
        "colab_type": "code",
        "outputId": "cab10fdc-ad8c-41b2-8d4f-e8b62c9cdd88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cl6SUj6Cyofi",
        "colab_type": "code",
        "outputId": "4f72ea54-48dc-4c1d-ece5-6003f1c827af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_features = load(open(\"drive/My Drive/CNN-LSTM/train_wt.pkl\", \"rb\"))\n",
        "print('Photos: train=%d' % len(train_features))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Photos: train=25426\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Ag9M43_zxDR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "descriptions = {}\n",
        "import pandas as pd\n",
        "df = pd.read_csv('drive/My Drive/CNN-LSTM/results.csv',delimiter='|')\n",
        "\n",
        "c = 0\n",
        "x = []\n",
        "for i,j in zip(df['image_name'],df[' comment']):\n",
        "  j = str(j)\n",
        "  x.append(j)\n",
        "  if c == 4:\n",
        "    c=0\n",
        "    descriptions[i] = x\n",
        "    x = []\n",
        "    continue\n",
        "  c += 1\n",
        "\n",
        "def save_descriptions(descriptions, filename):\n",
        "\tlines = list()\n",
        "\tfor key, desc_list in descriptions.items():\n",
        "\t\tfor desc in desc_list:\n",
        "\t\t\tlines.append(key + ' ' + desc)\n",
        "\tdata = '\\n'.join(lines)\n",
        "\tfile = open(filename, 'w')\n",
        "\tfile.write(data)\n",
        "\tfile.close()\n",
        "\n",
        "save_descriptions(descriptions, 'descriptions.txt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JegwltA02WyS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ba2180ea-e2e0-410d-e83d-ce66cd8e1832"
      },
      "source": [
        "len(train_features)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25426"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7TFymjW8naZU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "03ab6850-522c-429f-c8ea-6392438a3c44"
      },
      "source": [
        "len(descriptions) - 25426"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6357"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qy4yOXez9Oj",
        "colab_type": "code",
        "outputId": "93ff1c24-1e47-4dd7-96c3-a1f5d0ca3ff5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "c = 0\n",
        "mc = 6357\n",
        "test_img = []\n",
        "test = []\n",
        "train_img = []\n",
        "train = []\n",
        "\n",
        "\n",
        "for i in descriptions:\n",
        "  if c >= mc:\n",
        "    train_img.append(path+str(i))\n",
        "    train.append(i)\n",
        "  else:\n",
        "    test_img.append(path+str(i))\n",
        "    test.append(i)\n",
        "  c+=1\n",
        "  \n",
        "def load_doc(filename):\n",
        "\t# open the file as read only\n",
        "\tfile = open(filename, 'r')\n",
        "\t# read all text\n",
        "\ttext = file.read()\n",
        "\t# close the file\n",
        "\tfile.close()\n",
        "\treturn text\n",
        "\n",
        "# load clean descriptions into memory\n",
        "def load_clean_descriptions(filename, dataset):\n",
        "\t# load document\n",
        "\tdoc = load_doc(filename)\n",
        "\tdescriptions = dict()\n",
        "\tfor line in doc.split('\\n'):\n",
        "\t\t# split line by white space\n",
        "\t\ttokens = line.split()\n",
        "\t\t# split id from description\n",
        "\t\timage_id, image_desc = tokens[0], tokens[1:]\n",
        "\t\t# skip images not in the set\n",
        "\t\tif image_id in dataset:\n",
        "\t\t\t# create list\n",
        "\t\t\tif image_id not in descriptions:\n",
        "\t\t\t\tdescriptions[image_id] = list()\n",
        "\t\t\t# wrap description in tokens\n",
        "\t\t\tdesc = 'startseq ' + ' '.join(image_desc) + ' endseq'\n",
        "\t\t\t# store\n",
        "\t\t\tdescriptions[image_id].append(desc)\n",
        "\treturn descriptions\n",
        "\n",
        "# descriptions\n",
        "train_descriptions = load_clean_descriptions('descriptions.txt', train)\n",
        "print('Descriptions: train=%d' % len(train_descriptions))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Descriptions: train=25426\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zeAnbCxVzT9O",
        "colab_type": "code",
        "outputId": "29c634c9-4e91-4ecd-d06a-eff6720ea783",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "all_train_captions = []\n",
        "for key, val in train_descriptions.items():\n",
        "    for cap in val:\n",
        "        all_train_captions.append(cap)\n",
        "len(all_train_captions)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "127130"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fXin7mB3zgBw",
        "colab_type": "code",
        "outputId": "3f5a5754-5010-4a96-f415-745311fbac40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "word_count_threshold = 10\n",
        "word_counts = {}\n",
        "nsents = 0\n",
        "for sent in all_train_captions:\n",
        "    nsents += 1\n",
        "    for w in sent.split(' '):\n",
        "        word_counts[w] = word_counts.get(w, 0) + 1\n",
        "\n",
        "vocab = [w for w in word_counts if word_counts[w] >= word_count_threshold]\n",
        "print('preprocessed words %d -> %d' % (len(word_counts), len(vocab)))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "preprocessed words 21477 -> 5067\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "560twdsP0KD0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ixtoword = {}\n",
        "wordtoix = {}\n",
        "\n",
        "ix = 1\n",
        "for w in vocab:\n",
        "    wordtoix[w] = ix\n",
        "    ixtoword[ix] = w\n",
        "    ix += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DysXt0MM9P-I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "json = json.dumps(ixtoword)\n",
        "f = open(\"ixtoword.json\",\"w\")\n",
        "f.write(json)\n",
        "f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYhJIUsQ1su-",
        "colab_type": "code",
        "outputId": "6396c0f4-b744-4492-ef46-ceca083d519c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "vocab_size = len(ixtoword) + 1 # one for appended 0's\n",
        "vocab_size"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5068"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JppMh19d4BPC",
        "colab_type": "code",
        "outputId": "6044bc66-d1ad-4046-e33b-e470406e5a19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# convert a dictionary of clean descriptions to a list of descriptions\n",
        "def to_lines(descriptions):\n",
        "\tall_desc = list()\n",
        "\tfor key in descriptions.keys():\n",
        "\t\t[all_desc.append(d) for d in descriptions[key]]\n",
        "\treturn all_desc\n",
        "\n",
        "# calculate the length of the description with the most words\n",
        "def max_length(descriptions):\n",
        "\tlines = to_lines(descriptions)\n",
        "\treturn max(len(d.split()) for d in lines)\n",
        "\n",
        "# determine the maximum sequence length\n",
        "max_length = max_length(train_descriptions)\n",
        "print('Description Length: %d' % max_length)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Description Length: 77\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pogv-y1o4G6Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def data_generator(descriptions, photos, wordtoix, max_length, num_photos_per_batch):\n",
        "    X1, X2, y = list(), list(), list()\n",
        "    n=0\n",
        "    # loop for ever over images\n",
        "    while 1:\n",
        "        for key, desc_list in descriptions.items():\n",
        "            n+=1\n",
        "            # retrieve the photo feature\n",
        "            photo = photos[key]\n",
        "            for desc in desc_list:\n",
        "                # encode the sequence\n",
        "                seq = [wordtoix[word] for word in desc.split(' ') if word in wordtoix]\n",
        "                # split one sequence into multiple X, y pairs\n",
        "                for i in range(1, len(seq)):\n",
        "                    # split into input and output pair\n",
        "                    in_seq, out_seq = seq[:i], seq[i]\n",
        "                    # pad input sequence\n",
        "                    in_seq = pad_sequences([in_seq], maxlen=max_length)[0]\n",
        "                    # encode output sequence\n",
        "                    out_seq = to_categorical([out_seq], num_classes=vocab_size)[0]\n",
        "                    # store\n",
        "                    X1.append(photo)\n",
        "                    X2.append(in_seq)\n",
        "                    y.append(out_seq)\n",
        "            # yield the batch data\n",
        "            if n==num_photos_per_batch:\n",
        "                yield [[array(X1), array(X2)], array(y)]\n",
        "                X1, X2, y = list(), list(), list()\n",
        "                n=0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBW1htMpMIeh",
        "colab_type": "code",
        "outputId": "ef96b285-0a6d-4106-b131-2dad68b431db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "glove_dir = 'drive/My Drive/CNN-LSTM/'\n",
        "embeddings_index = {} # empty dictionary\n",
        "f = open(os.path.join(glove_dir, 'glove.6B.200d.txt'), encoding=\"utf-8\")\n",
        "\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()\n",
        "print('Found %s word vectors.' % len(embeddings_index))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 400000 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E1kOoV8IMNlB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_dim = 200\n",
        "\n",
        "# Get 200-dim dense vector for each of the 10000 words in out vocabulary\n",
        "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
        "\n",
        "for word, i in wordtoix.items():\n",
        "    #if i < max_words:\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        # Words not found in the embedding index will be all zeros\n",
        "        embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQG071Pe4Ye-",
        "colab_type": "code",
        "outputId": "a823c1c8-f083-41eb-b062-741a6eb96468",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "embedding_matrix.shape\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5068, 200)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OV_NYTlZ4bG5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inputs1 = Input(shape=(2048,))\n",
        "fe1 = Dropout(0.2)(inputs1)\n",
        "fe2 = Dense(256, activation='relu')(fe1)\n",
        "inputs2 = Input(shape=(max_length,))\n",
        "se1 = Embedding(vocab_size, embedding_dim, mask_zero=True)(inputs2)\n",
        "se2 = Dropout(0.3)(se1)\n",
        "se3 = LSTM(256)(se2)\n",
        "decoder1 = add([fe2, se3])\n",
        "decoder2 = Dense(256, activation='relu')(decoder1)\n",
        "outputs = Dense(vocab_size, activation='softmax')(decoder2)\n",
        "model = Model(inputs=[inputs1, inputs2], outputs=outputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xo32AhL74d_Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.layers[2].set_weights([embedding_matrix])\n",
        "model.layers[2].trainable = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f73Ztrvd4rav",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hc7oby454uMQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = 10\n",
        "number_pics_per_bath = 3\n",
        "steps = len(train_descriptions)//number_pics_per_bath"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgGraTs6nyLR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from keras.models import load_model\n",
        "\n",
        "# # returns a compiled model\n",
        "# # identical to the previous one\n",
        "# model = load_model('drive/My Drive/CNN-LSTM/modelfinal4.h5')\n",
        "# # model = load_model('model_8.h5')\n",
        "# `\n",
        "# `\n",
        "\n",
        "\n",
        "# # continue training from 7-9"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0n2h0Pa4v7J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BCz7mwMMollB",
        "colab_type": "code",
        "outputId": "9fd77dc6-5a6e-40bd-914c-2789e6ee0762",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "for i in range(epochs):\n",
        "    generator = data_generator(train_descriptions, train_features, wordtoix, max_length, number_pics_per_bath)\n",
        "    model.fit_generator(generator, epochs=1, steps_per_epoch=steps, verbose=1)\n",
        "    model.save('model_weights/model_' + str(i) + '.h5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n",
            "2539/8475 [=======>......................] - ETA: 29:30 - loss: 3.9076"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCYv7v7Roji0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(epochs):\n",
        "    generator = data_generator(train_descriptions, train_features, wordtoix, max_length, number_pics_per_bath)\n",
        "    model.fit_generator(generator, epochs=1, steps_per_epoch=steps, verbose=1)\n",
        "    model.save('model_weights/model_' + str(i) + '.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZZMk73944eL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model.optimizer.learning_rate = 0.0001\n",
        "epochs = 10\n",
        "number_pics_per_bath = 6\n",
        "steps = len(train_descriptions)//number_pics_per_bath"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7V-GBVyOoz0E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "\n",
        "opt = keras.optimizers.Adam(learning_rate=0.0001)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=opt)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGRo_gielcm_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(10):\n",
        "    generator = data_generator(train_descriptions, train_features, wordtoix, max_length, number_pics_per_bath)\n",
        "    model.fit_generator(generator, epochs=1, steps_per_epoch=steps, verbose=1)\n",
        "    model.save('drive/My Drive/CNN-LSTM/modelfinal'+ str(6+i) + '.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLSrvxH0S_85",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LsFcqzsxpBPN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('drive/My Drive/CNN-LSTM/FinalModel' + '.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LbATYuSPN1q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "# returns a compiled model\n",
        "# identical to the previous one\n",
        "model = load_model('drive/My Drive/CNN-LSTM/FinalModel.h5')\n",
        "\n",
        "# continue training from 7-9"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "luVtdnQBprro",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoding_test  = load(open(\"drive/My Drive/CNN-LSTM/test_wt.pkl\", \"rb\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1SDuEFYSRej",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRI7SEUJSU1N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(encoding_test)\n",
        "def greedySearch(photo):\n",
        "    in_text = 'startseq'\n",
        "    for i in range(max_length):\n",
        "        sequence = [wordtoix[w] for w in in_text.split() if w in wordtoix]\n",
        "        sequence = pad_sequences([sequence], maxlen=max_length)\n",
        "        yhat = model.predict([photo,sequence], verbose=0)\n",
        "        yhat = np.argmax(yhat)\n",
        "        print(yhat)\n",
        "        word = ixtoword[str(yhat)]\n",
        "        in_text += ' ' + word\n",
        "        if word == 'endseq':\n",
        "            break\n",
        "    final = in_text.split()\n",
        "    final = final[1:-1]\n",
        "    final = ' '.join(final)\n",
        "    return final\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PsXe5jwzGK5K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def greedySearch(photo):\n",
        "    in_text = 'startseq'\n",
        "    for i in range(max_length):\n",
        "        sequence = [wordtoix[w] for w in in_text.split() if w in wordtoix]\n",
        "        sequence = pad_sequences([sequence], maxlen=max_length)\n",
        "        yhat = model.predict([photo,sequence], verbose=0)\n",
        "        yhat = np.argmax(yhat)\n",
        "\n",
        "        word = ixtoword[(yhat)]\n",
        "        in_text += ' ' + word\n",
        "        if word == 'endseq':\n",
        "            break\n",
        "    final = in_text.split()\n",
        "    final = final[1:-1]\n",
        "    final = ' '.join(final)\n",
        "    return final\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2HKJ69lGPAp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range (50):\n",
        "  pic = list(encoding_test.keys())[i]\n",
        "  image = encoding_test[pic].reshape((1,2048))\n",
        "  x=plt.imread(path+pic)\n",
        "  plt.imshow(x)\n",
        "  plt.show()\n",
        "  print(\"Greedy:\",greedySearch(image))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zhf8cQE1GPyX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2iGr7dM9Gp5f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}